{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 7494 new Autopool transfers for autoETH on eth\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from web3 import Web3\n",
    "\n",
    "from mainnet_launch.constants import ALL_AUTOPOOLS, ALL_CHAINS, profile_function, AutopoolConstants\n",
    "from mainnet_launch.database.schema.full import AutopoolDeposit\n",
    "from mainnet_launch.database.schema.postgres_operations import _exec_sql_and_cache\n",
    "from mainnet_launch.data_fetching.get_events import fetch_events\n",
    "from mainnet_launch.database.schema.ensure_tables_are_current.using_onchain.update_transactions import (\n",
    "    ensure_all_transactions_are_saved_in_db,\n",
    "    insert_avoid_conflicts,\n",
    ")\n",
    "\n",
    "from mainnet_launch.abis import AUTOPOOL_VAULT_ABI\n",
    "\n",
    "\n",
    "def get_highest_already_fetched_autopool_transfer_block() -> dict[str, int]:\n",
    "    # TODO this can be generic\n",
    "    query = \"\"\"\n",
    "        WITH autopool_transfers_block AS (\n",
    "            SELECT\n",
    "                autopool_transfers.autopool_vault_address,\n",
    "                transactions.block\n",
    "            FROM autopool_transfers\n",
    "            JOIN transactions\n",
    "              ON autopool_transfers.tx_hash = autopool_transfers.tx_hash\n",
    "        )\n",
    "        SELECT\n",
    "            autopool_vault_address,\n",
    "            MAX(block) AS max_block\n",
    "        FROM autopool_transfers_block\n",
    "        GROUP BY autopool_vault_address;\n",
    "    \"\"\"\n",
    "    df = _exec_sql_and_cache(query)\n",
    "    highest = df.set_index(\"autopool_vault_address\")[\"max_block\"].to_dict() if not df.empty else {}\n",
    "\n",
    "    for ap in ALL_AUTOPOOLS:\n",
    "        if ap.autopool_eth_addr not in highest:\n",
    "            # Default to the deploy block if no rows exist yet\n",
    "            highest[ap.autopool_eth_addr] = ap.block_deployed\n",
    "    return highest\n",
    "\n",
    "\n",
    "def ensure_autopool_transfers_are_current():\n",
    "    highest_block_by_pool = get_highest_already_fetched_autopool_transfer_block()\n",
    "    transfer_dfs: list[pd.DataFrame] = []\n",
    "\n",
    "    for autopool in ALL_AUTOPOOLS:\n",
    "        contract = autopool.chain.client.eth.contract(\n",
    "            address=autopool.autopool_eth_addr,\n",
    "            abi=AUTOPOOL_VAULT_ABI,\n",
    "        )\n",
    "\n",
    "        transfer_df = fetch_events(\n",
    "            contract.events.Transfer,\n",
    "            chain=autopool.chain,\n",
    "            start_block=highest_block_by_pool[autopool.autopool_eth_addr],\n",
    "        )\n",
    "        transfer_df[\"value\"] = transfer_df[\"value\"].apply(lambda x: int(x) / 1e18)  # always 1e18\n",
    "        transfer_df[\"autopool_vault_address\"] = autopool.autopool_eth_addr\n",
    "        transfer_df[\"chain_id\"] = autopool.chain.chain_id\n",
    "        transfer_df[\"from_address\"] = transfer_df[\"from\"].apply(lambda x: Web3.toChecksumAddress(x))\n",
    "        transfer_df[\"to_address\"] = transfer_df[\"to\"].apply(lambda x: Web3.toChecksumAddress(x))\n",
    "\n",
    "        if transfer_df.empty:\n",
    "            continue\n",
    "        print(f\"Fetched {len(transfer_df)} new Autopool transfers for {autopool.name} on {autopool.chain.name}\")\n",
    "        transfer_dfs.append(transfer_df)\n",
    "        break\n",
    "\n",
    "    if len(transfer_dfs) == 0:\n",
    "        return  # early exit, nothing to do\n",
    "\n",
    "    all_df = pd.concat(transfer_dfs, ignore_index=True)\n",
    "    return all_df\n",
    "\n",
    "    for chain in ALL_CHAINS:\n",
    "        txs = list(all_df.loc[all_df[\"chain_id\"] == chain.chain_id, \"tx_hash\"].drop_duplicates())\n",
    "        if txs:\n",
    "            ensure_all_transactions_are_saved_in_db(txs, chain)\n",
    "\n",
    "    # Build ORM rows\n",
    "    new_rows = all_df.apply(\n",
    "        lambda r: AutopoolDeposit(\n",
    "            tx_hash=r[\"tx_hash\"],\n",
    "            autopool_vault_address=r[\"autopool_vault_address\"],\n",
    "            chain_id=int(r[\"chain_id\"]),\n",
    "            block=int(r[\"block\"]),\n",
    "            shares=float(r[\"shares\"]),\n",
    "            base_asset_amount=float(r[\"base_asset_amount\"]),\n",
    "            user=r[\"user\"],\n",
    "            nav_per_share=str(r[\"nav_per_share\"]),\n",
    "        ),\n",
    "        axis=1,\n",
    "    ).to_list()\n",
    "\n",
    "    if new_rows:\n",
    "        insert_avoid_conflicts(new_rows, AutopoolDeposit)\n",
    "\n",
    "\n",
    "df = ensure_autopool_transfers_are_current()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mainnet-launch-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
