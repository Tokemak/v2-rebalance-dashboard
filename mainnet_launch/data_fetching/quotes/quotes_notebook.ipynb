{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 10:54:34.832 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-06-25 10:54:34.878 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 10:54:34.939 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/pb/Library/Caches/pypoetry/virtualenvs/mainnet-launch-FtycU18g-py3.10/lib/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-06-25 10:54:34.939 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 10:54:34.940 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 10:54:34.940 No runtime found, using MemoryCacheStorageManager\n",
      "2025-06-25 10:54:35.446 Thread 'Thread-4': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 10:54:35.446 Thread 'Thread-4': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 10:54:36.877 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 10:54:36.877 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 10:54:36.878 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 10:54:36.879 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 10:54:36.879 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 10:54:37.385 Thread 'Thread-5': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 10:54:37.385 Thread 'Thread-5': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 10:54:37.736 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-25 10:54:37.737 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Tokens(token_address='0x0655977FEb2f289A4aB78af67BAB0d17aAb84367', chain_id=1, symbol='scrvUSD', name='Savings crvUSD', decimals=18),\n",
       " Tokens(token_address='0x57aB1E0003F623289CD798B1824Be09a793e4Bec', chain_id=1, symbol='reUSD', name='Resupply USD', decimals=18),\n",
       " Tokens(token_address='0x865377367054516e17014CcdED1e7d814EDC9ce4', chain_id=1, symbol='DOLA', name='Dola USD Stablecoin', decimals=18),\n",
       " Tokens(token_address='0xa3931d71877C0E7a3148CB7Eb4463524FEc27fbD', chain_id=1, symbol='sUSDS', name='Savings USDS', decimals=18),\n",
       " Tokens(token_address='0xBC6DA0FE9aD5f3b0d58160288917AA56653660E9', chain_id=1, symbol='alUSD', name='Alchemix USD', decimals=18),\n",
       " Tokens(token_address='0xb45ad160634c528Cc3D2926d9807104FA3157305', chain_id=1, symbol='sDOLA', name='Staked Dola', decimals=18),\n",
       " Tokens(token_address='0x66a1E37c9b0eAddca17d3662D6c05F4DECf3e110', chain_id=1, symbol='USR', name='Resolv USD', decimals=18),\n",
       " Tokens(token_address='0x9D39A5DE30e57443BfF2A8307A4256c8797A3497', chain_id=1, symbol='sUSDe', name='Staked USDe', decimals=18),\n",
       " Tokens(token_address='0x15700B564Ca08D9439C58cA5053166E8317aa138', chain_id=1, symbol='deUSD', name='deUSD', decimals=18)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "\n",
    "from mainnet_launch.constants import *\n",
    "from mainnet_launch.database.schema.full import *\n",
    "from mainnet_launch.database.schema.postgres_operations import *\n",
    "import numpy as np\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "_rate_limit = asyncio.Semaphore(10)\n",
    "_session: aiohttp.ClientSession | None = None\n",
    "\n",
    "\n",
    "async def get_session() -> aiohttp.ClientSession:\n",
    "    global _session\n",
    "    if _session is None or _session.closed:\n",
    "        _session = aiohttp.ClientSession()\n",
    "    return _session\n",
    "\n",
    "\n",
    "async def fetch_swap_quote(\n",
    "    chain_id: int,\n",
    "    sell_token: str,\n",
    "    buy_token: str,\n",
    "    sell_amount: int,\n",
    "    system_name: str = \"gen3\",\n",
    "    slippage_bps: int = 50,\n",
    "    include_sources: str = \"\",\n",
    "    exclude_sources: str = \"Bebop\",\n",
    "    sell_all: bool = True,\n",
    "    timeout_ms: int = None,\n",
    "    transfer_to_caller: bool = True,\n",
    ") -> dict:\n",
    "    async with _rate_limit:\n",
    "        url = \"https://swaps-pricing.tokemaklabs.com/swap-quote-v2\"\n",
    "        payload = {\n",
    "            \"chainId\": chain_id,\n",
    "            \"systemName\": system_name,\n",
    "            \"slippageBps\": slippage_bps,\n",
    "            \"taker\": DEAD_ADDRESS,\n",
    "            \"sellToken\": sell_token,\n",
    "            \"buyToken\": buy_token,\n",
    "            \"sellAmount\": sell_amount,\n",
    "            \"includeSources\": include_sources,\n",
    "            \"excludeSources\": exclude_sources,\n",
    "            \"sellAll\": sell_all,\n",
    "            \"timeoutMS\": str(timeout_ms) if timeout_ms is not None else \"\",\n",
    "            \"transferToCaller\": str(transfer_to_caller),\n",
    "        }\n",
    "\n",
    "        session = await get_session()\n",
    "        async with session.post(url, json=payload) as resp:\n",
    "            try:\n",
    "                resp.raise_for_status()\n",
    "                data = await resp.json()\n",
    "                data.update(payload)\n",
    "            except Exception as e:\n",
    "                data = {\"error\": str(e), **payload}\n",
    "                raise e\n",
    "        return data\n",
    "\n",
    "\n",
    "async def fetch_quote_size_df(\n",
    "    token_orms: list[Tokens], sizes: list[float], autopool: AutopoolConstants\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    tasks = []\n",
    "\n",
    "    for size in sizes:\n",
    "        for t in token_orms:\n",
    "\n",
    "            tasks.append(\n",
    "                fetch_swap_quote(\n",
    "                    chain_id=t.chain_id,\n",
    "                    sell_token=t.token_address,\n",
    "                    buy_token=autopool.base_asset,\n",
    "                    sell_amount=int(size * 10**t.decimals),\n",
    "                )\n",
    "            )\n",
    "    quotes = await asyncio.gather(*tasks)\n",
    "    quote_df = pd.DataFrame.from_records(quotes)\n",
    "    return quote_df\n",
    "\n",
    "\n",
    "async def fetch_quote_df(\n",
    "    token_orms: list[Tokens], base_sell_amount: float, autopool: AutopoolConstants\n",
    ") -> pd.DataFrame:\n",
    "    # launch all requests in parallel\n",
    "    quotes = await asyncio.gather(\n",
    "        *(\n",
    "            fetch_swap_quote(\n",
    "                chain_id=t.chain_id,\n",
    "                sell_token=t.token_address,\n",
    "                buy_token=autopool.base_asset,\n",
    "                sell_amount=int(base_sell_amount * 10**t.decimals),\n",
    "            )\n",
    "            for t in token_orms\n",
    "        )\n",
    "    )\n",
    "    return pd.DataFrame.from_records(quotes)\n",
    "\n",
    "\n",
    "from mainnet_launch.pages.autopool_exposure.allocation_over_time import _fetch_tvl_by_asset_and_destination\n",
    "\n",
    "\n",
    "autopool = AUTO_DOLA\n",
    "\n",
    "safe_value_by_destination, safe_value_by_asset, backing_value_by_destination, quantity_by_asset = (\n",
    "    _fetch_tvl_by_asset_and_destination(autopool)\n",
    ")\n",
    "token_orms = get_full_table_as_orm(Tokens, where_clause=Tokens.chain_id == autopool.chain.chain_id)\n",
    "\n",
    "# note this introduces some latency, but not a big deal imo\n",
    "quantity_by_asset\n",
    "\n",
    "\n",
    "latest_quantity_by_assets = quantity_by_asset.iloc[-1]\n",
    "tokens_to_get_quotes_for = [t for t in token_orms if t.symbol in latest_quantity_by_assets.index ]\n",
    "tokens_to_get_quotes_for\n",
    "\n",
    "\n",
    "\n",
    "token_symbol_to_token_orm = {t.symbol: t for t in token_orms}\n",
    "all_quotes = []\n",
    "for token_symbol, normalized_quantity in latest_quantity_by_assets.items():\n",
    "    this_token_orm: Tokens = token_symbol_to_token_orm[token_symbol]\n",
    "    unscaled_quantity = int(normalized_quantity * (10 ** (this_token_orm.decimals) ))\n",
    "    print(token_symbol_to_token_orm[token_symbol],  normalized_quantity, unscaled_quantity)\n",
    "\n",
    "\n",
    "    for scale in range(1,10):\n",
    "        percent_of_assets_to_liquidate =  scale / 10\n",
    "\n",
    "        quote = fetch_swap_quote(\n",
    "                    chain_id=autopool.chain.chain_id,\n",
    "                    sell_token=this_token_orm.token_address,\n",
    "                    buy_token=autopool.base_asset,\n",
    "                    sell_amount=int(unscaled_quantity * percent_of_assets_to_liquidate)\n",
    "                )\n",
    "        all_quotes.append(quote)\n",
    "        break\n",
    "\n",
    "a_quote = await all_quotes[0]\n",
    "a_quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens(token_address='0x865377367054516e17014CcdED1e7d814EDC9ce4', chain_id=1, symbol='DOLA', name='Dola USD Stablecoin', decimals=18) 142110.23921932117 142110239219321178947584\n",
      "Tokens(token_address='0x66a1E37c9b0eAddca17d3662D6c05F4DECf3e110', chain_id=1, symbol='USR', name='Resolv USD', decimals=18) 0.0 0\n",
      "Tokens(token_address='0xBC6DA0FE9aD5f3b0d58160288917AA56653660E9', chain_id=1, symbol='alUSD', name='Alchemix USD', decimals=18) 92269.45978062181 92269459780621807124480\n",
      "Tokens(token_address='0x15700B564Ca08D9439C58cA5053166E8317aa138', chain_id=1, symbol='deUSD', name='deUSD', decimals=18) 0.0 0\n",
      "Tokens(token_address='0x57aB1E0003F623289CD798B1824Be09a793e4Bec', chain_id=1, symbol='reUSD', name='Resupply USD', decimals=18) 1108113.2814035171 1108113281403517050814464\n",
      "Tokens(token_address='0xb45ad160634c528Cc3D2926d9807104FA3157305', chain_id=1, symbol='sDOLA', name='Staked Dola', decimals=18) 2770902.9539302196 2770902953930219845582848\n",
      "Tokens(token_address='0xa3931d71877C0E7a3148CB7Eb4463524FEc27fbD', chain_id=1, symbol='sUSDS', name='Savings USDS', decimals=18) 0.0 0\n",
      "Tokens(token_address='0x9D39A5DE30e57443BfF2A8307A4256c8797A3497', chain_id=1, symbol='sUSDe', name='Staked USDe', decimals=18) 98287.01127638962 98287011276389619859456\n",
      "Tokens(token_address='0x0655977FEb2f289A4aB78af67BAB0d17aAb84367', chain_id=1, symbol='scrvUSD', name='Savings crvUSD', decimals=18) 292884.51243819273 292884512438192716120064\n"
     ]
    },
    {
     "ename": "ClientResponseError",
     "evalue": "400, message='Bad Request', url='https://swaps-pricing.tokemaklabs.com/swap-quote-v2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientResponseError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m         all_quotes\u001b[38;5;241m.\u001b[39mappend(quote)\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m a_quote \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m all_quotes[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     22\u001b[0m a_quote\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# quote_df =  pd.DataFrame.from_records(await asyncio.gather( *all_quotes))\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# quotes_df\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 64\u001b[0m, in \u001b[0;36mfetch_swap_quote\u001b[0;34m(chain_id, sell_token, buy_token, sell_amount, system_name, slippage_bps, include_sources, exclude_sources, sell_all, timeout_ms, transfer_to_caller)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m         data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(e), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpayload}\n\u001b[0;32m---> 64\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "Cell \u001b[0;32mIn[1], line 59\u001b[0m, in \u001b[0;36mfetch_swap_quote\u001b[0;34m(chain_id, sell_token, buy_token, sell_amount, system_name, slippage_bps, include_sources, exclude_sources, sell_all, timeout_ms, transfer_to_caller)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m session\u001b[38;5;241m.\u001b[39mpost(url, json\u001b[38;5;241m=\u001b[39mpayload) \u001b[38;5;28;01mas\u001b[39;00m resp:\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m         \u001b[43mresp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     61\u001b[0m         data\u001b[38;5;241m.\u001b[39mupdate(payload)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/mainnet-launch-FtycU18g-py3.10/lib/python3.10/site-packages/aiohttp/client_reqrep.py:1161\u001b[0m, in \u001b[0;36mClientResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_context:\n\u001b[1;32m   1159\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m-> 1161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ClientResponseError(\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_info,\n\u001b[1;32m   1163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory,\n\u001b[1;32m   1164\u001b[0m     status\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m   1165\u001b[0m     message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreason,\n\u001b[1;32m   1166\u001b[0m     headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m   1167\u001b[0m )\n",
      "\u001b[0;31mClientResponseError\u001b[0m: 400, message='Bad Request', url='https://swaps-pricing.tokemaklabs.com/swap-quote-v2'"
     ]
    }
   ],
   "source": [
    "\n",
    "# quote_df =  pd.DataFrame.from_records(await asyncio.gather( *all_quotes))\n",
    "\n",
    "# quotes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_quantity_by_assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_quantity_by_assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quotes_at_scale\n",
    "import ast\n",
    "\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.templates.default = None\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"/Users/pb/Documents/Github/Tokemak/v2-rebalance-dashboard/mainnet_launch/data_fetching/quotes/sonicUSD_scale_quotes.csv\"\n",
    ")\n",
    "\n",
    "df[\"min_buy_scaled\"] = df[\"minBuyAmount\"].apply(lambda x: int(x) / 1e6 if x > 0 else np.nan)\n",
    "df[\"buy_scaled\"] = df[\"buyAmount\"].apply(lambda x: int(x) / 1e6 if x > 0 else np.nan)\n",
    "\n",
    "# scale sellAmount by its own per-row decimals\n",
    "df[\"sell_amount_scaled\"] = df.apply(lambda row: int(row[\"sellAmount\"]) / (10 ** row[\"decimals\"]), axis=1)\n",
    "\n",
    "df[\"buy_ratio\"] = df[\"buy_scaled\"] / df[\"sell_amount_scaled\"]\n",
    "df[\"min_buy_ratio\"] = df[\"min_buy_scaled\"] / df[\"sell_amount_scaled\"]\n",
    "\n",
    "price_df = df.pivot(columns=\"symbol\", index=\"sell_amount_scaled\", values=\"buy_scaled\")\n",
    "ratio_df = df.pivot(columns=\"symbol\", index=\"sell_amount_scaled\", values=\"buy_ratio\")\n",
    "ratio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not symetrical down,\n",
    "\n",
    "# all the near the same time?\n",
    "\n",
    "# not really certian there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(ratio_df, title=\"sonic_USD_ratio\", log_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"symbol\"] == \"escUSD1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quotes fail, for > 100 frxUSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"quotes_records2.csv\")\n",
    "df[\"fullQuoteDetails_parsed\"] = df[\"fullQuoteDetails\"].apply(ast.literal_eval)\n",
    "\n",
    "\n",
    "def extract_block(row):\n",
    "\n",
    "    if \"data\" in row[\"fullQuoteDetails_parsed\"]:\n",
    "        return int(row[\"fullQuoteDetails_parsed\"][\"data\"][\"blockNumber\"])\n",
    "    elif \"quote\" in row[\"fullQuoteDetails_parsed\"]:\n",
    "        return int(row[\"fullQuoteDetails_parsed\"][\"quote\"][\"blockNumber\"])\n",
    "\n",
    "\n",
    "df[\"block\"] = df.apply(extract_block, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"symbol\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# did something change this minute with the sell able toekns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"min_buy_scaled\"] = df[\"minBuyAmount\"].apply(lambda x: int(x) / 1e6)\n",
    "df[\"buy_scaled\"] = df[\"buyAmount\"].apply(lambda x: int(x) / 1e6)\n",
    "df[\"sell_amount_scaled\"] = df.apply(lambda row: int(row[\"sellAmount\"]) / (10 ** row[\"decimals\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"symbol\", \"min_buy_scaled\", \"buy_scaled\", \"sell_amount_scaled\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.scatter(df, x=df[\"block\"], y=\"min_buy_scaled\", color=\"symbol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df, x=df.index, y=\"buy_scaled\", color=\"symbol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mainnet-launch-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
