{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autopool: autoETH\n",
      "Number of events without rebalance plans: 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7208a894c02a44bdbb1884b50672d387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Augmenting and saving plans (sequential):   0%|          | 0/643 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 643 events\n",
      "Autopool: baseETH\n",
      "Number of events without rebalance plans: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee6f1c31a5db44a2b12e36739fb1891f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Augmenting and saving plans (sequential):   0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 265 events\n"
     ]
    }
   ],
   "source": [
    "from mainnet_launch.data_fetching.get_state_by_block import (\n",
    "    get_state_by_one_block,\n",
    "    build_blocks_to_use,\n",
    "    get_raw_state_by_blocks,\n",
    "    safe_normalize_6_with_bool_success,\n",
    "    safe_normalize_with_bool_success,\n",
    "    identity_with_bool_success,\n",
    "    make_dummy_1_call\n",
    "\n",
    ")\n",
    "from multicall import Call\n",
    "\n",
    "from mainnet_launch.database.postgres_operations import (\n",
    "    get_full_table_as_df,\n",
    "    get_full_table_as_df_with_tx_hash,\n",
    ")\n",
    "from mainnet_launch.database.schema.full import (\n",
    "    RebalanceEvents,\n",
    "    RebalancePlans,\n",
    "    Blocks,\n",
    ")\n",
    "\n",
    "from mainnet_launch.data_fetching.defi_llama.fetch_timestamp import fetch_blocks_by_unix_timestamps_defillama\n",
    "\n",
    "from mainnet_launch.constants import (\n",
    "    WORKING_DATA_DIR,\n",
    "    AutopoolConstants,\n",
    "    ChainData,\n",
    "    AUTO_ETH,\n",
    "    BASE_ETH,\n",
    "    AUTO_LRT,\n",
    "    BAL_ETH,\n",
    "    DINERO_ETH,\n",
    ")\n",
    "from mainnet_launch.data_fetching.internal.s3_helper import fetch_rebalance_plan_json_no_s3_client\n",
    "from mainnet_launch.pages.autopool.autopool_diagnostics.lens_contract import build_proxyGetDestinationSummaryStats_call\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "\n",
    "pio.templates.default = None\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "def build_dv_to_sig_to_vp(autopool:AutopoolConstants):\n",
    "    # autopool = BASE_ETH\n",
    "    events = get_full_table_as_df_with_tx_hash(\n",
    "        RebalanceEvents, where_clause=RebalanceEvents.autopool_vault_address == autopool.autopool_eth_addr\n",
    "    )\n",
    "    # mainnet_blocks = get_full_table_as_df(Blocks, where_clause=Blocks.chain_id == autopool.chain.chain_id).sort_values(\n",
    "    #     \"block\"\n",
    "    # )\n",
    "    destinations = set(events[\"destination_out\"].unique().tolist() + events[\"destination_in\"].unique().tolist())\n",
    "    calls = [Call(address, \"getStats()(address)\", [(address, identity_with_bool_success)]) for address in destinations]\n",
    "\n",
    "    destination_vault_address_to_stats_contract = get_state_by_one_block(\n",
    "        calls, autopool.chain.get_block_near_top(), autopool.chain\n",
    "    )\n",
    "\n",
    "    calls = [\n",
    "        Call(stats_contract, \"underlyerStats()(address)\", [(destination_vault, identity_with_bool_success)])\n",
    "        for destination_vault, stats_contract in destination_vault_address_to_stats_contract.items()\n",
    "        if stats_contract is not None\n",
    "    ]\n",
    "\n",
    "    destination_vault_to_underlyer = get_state_by_one_block(calls, autopool.chain.get_block_near_top(), autopool.chain)\n",
    "\n",
    "    calls = [\n",
    "        Call(stats_contract, \"pool()(address)\", [(destination_vault, identity_with_bool_success)])\n",
    "        for destination_vault, stats_contract in destination_vault_address_to_stats_contract.items()\n",
    "        if stats_contract is not None\n",
    "    ]\n",
    "    # virtual_price_call = \"    function get_virtual_price() external view returns (uint256);\"\n",
    "    destination_vault_to_pool = get_state_by_one_block(calls, autopool.chain.get_block_near_top(), autopool.chain)\n",
    "\n",
    "    # aredrom is getK() / totalSupply() instead of get_virtual_price()\n",
    "\n",
    "\n",
    "    destination_vault_to_pool['0x3772973f8F399D74488D5cF3276C032E0afC8A6f'] = '0x94B17476A93b3262d87B9a326965D1E91f9c13E7' # curvePool()(address)\n",
    "    destination_vault_to_pool['0xe4433D00Cf48BFE0C672d9949F2cd2c008bffC04'] = '0x6951bDC4734b9f7F3E1B74afeBC670c736A0EDB6' # curvePool()(address)\n",
    "    destination_vault_to_pool['0xc4Eb861e7b66f593482a3D7E8adc314f6eEDA30B'] = '0x88794C65550DeB6b4087B7552eCf295113794410' # balancerPool()(address)\n",
    "    destination_vault_to_pool['0x2C7120dCCF1c14A37A26A4955475d45d34a3d7E7'] = '0xA0D3707c569ff8C87FA923d3823eC5D81c98Be78' # getpool instadapp ETHv2\n",
    "    destination_vault_to_pool['0xd100c932801390fdeBcE11F26f611D4898b44236'] = '0x7f39C581F595B53c5cb19bD0b3f8dA6c935E2Ca0' # getPool wstETH (holding)\n",
    "    destination_vault_to_pool['0x945a4f719018edBa445ca67bDa43663C815835Ad'] = '0x91F0f34916Ca4E2cCe120116774b0e4fA0cdcaA8' # getPool wstETH (holding)\n",
    "\n",
    "\n",
    "    function_signatures = [\n",
    "        \"get_virtual_price()(uint256)\",\n",
    "        \"getRate()(uint256)\",\n",
    "        'stEthPerToken()(uint256)',\n",
    "        'exchangePrice()(uint256)',\n",
    "    ]\n",
    "\n",
    "    # Build calls to get virtual price for each pool\n",
    "    vp_calls = []\n",
    "    for destination_vault, pool_address in destination_vault_to_pool.items():\n",
    "        for function_signature in function_signatures:\n",
    "            vp_calls.append(\n",
    "                Call(\n",
    "                    pool_address,\n",
    "                    function_signature,\n",
    "                    [((destination_vault, pool_address, function_signature), safe_normalize_with_bool_success)]\n",
    "                )\n",
    "            )\n",
    "\n",
    "    virtual_prices = get_state_by_one_block(vp_calls, autopool.chain.get_block_near_top(), autopool.chain)\n",
    "    vp_df = pd.DataFrame.from_dict(virtual_prices, orient='index', columns=['virtual_price']).reset_index()\n",
    "    vp_df[['destination_vault', 'pool', 'function_signature']] = pd.DataFrame(vp_df['index'].tolist(), index=vp_df.index)\n",
    "\n",
    "\n",
    "    # destination_vault -> {function_signature: virtual_price_or_None}\n",
    "    dv_to_sig_to_vp = {}\n",
    "    for _, r in vp_df.iterrows():\n",
    "        dv  = r[\"destination_vault\"]\n",
    "        pool = r[\"pool\"]\n",
    "        sig = r[\"function_signature\"]\n",
    "        v   = r[\"virtual_price\"]\n",
    "        if pd.notna(v):\n",
    "            dv_to_sig_to_vp[dv] = (pool, sig)\n",
    "    \n",
    "    return dv_to_sig_to_vp\n",
    "\n",
    "\n",
    "# # Find destination vaults that don't have a valid virtual price mapping\n",
    "# destinations_without_vp = destinations - set(dv_to_sig_to_vp.keys())\n",
    "# print(f\"Destination vaults without virtual price: {len(destinations_without_vp)}\")\n",
    "# print(destinations_without_vp)\n",
    "\n",
    "\n",
    "def build_call_from_destination_vault(dv_to_sig_to_vp, destination_vault, dir):\n",
    "    if destination_vault not in dv_to_sig_to_vp:\n",
    "       return make_dummy_1_call(f'{dir} virtual_price')\n",
    "    pool, sig = dv_to_sig_to_vp[destination_vault]\n",
    "    return Call(\n",
    "        pool,\n",
    "        sig,\n",
    "        [(f'{dir} virtual_price', safe_normalize_with_bool_success)]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "class PlanVerificationError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def _validate_plan(plan_data: dict):\n",
    "    \"\"\"Raise a error if the plan is malformed\"\"\"\n",
    "    if plan_data[\"destinationOut\"] is None:\n",
    "        raise PlanVerificationError(\"destinationOut is None\")\n",
    "    if plan_data[\"destinationIn\"] is None:\n",
    "        raise PlanVerificationError(\"destinationIn is None\")\n",
    "\n",
    "\n",
    "def add_destination_summary_stats(dv_to_sig_to_vp:dict, plan_file_path: str, rebalance_block: int, autopool):\n",
    "    plan_data = fetch_rebalance_plan_json_no_s3_client(plan_file_path, autopool)\n",
    "    _validate_plan(plan_data)\n",
    "    destination_out_summary_stats_call = build_proxyGetDestinationSummaryStats_call(\n",
    "        \"out\", autopool, plan_data[\"destinationOut\"], direction=\"out\", amount=0\n",
    "    )\n",
    "    destination_in_summary_stats_call = build_proxyGetDestinationSummaryStats_call(\n",
    "        \"in\", autopool, plan_data[\"destinationIn\"], direction=\"in\", amount=0\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    stats_at_block = get_state_by_one_block(\n",
    "        [destination_out_summary_stats_call, destination_in_summary_stats_call], rebalance_block, autopool.chain\n",
    "    )\n",
    "    plan_data['destinationOutSummaryStats'] = stats_at_block\n",
    "\n",
    "    out_vp_call = build_call_from_destination_vault(dv_to_sig_to_vp, plan_data[\"destinationOut\"], 'out')\n",
    "    in_vp_call = build_call_from_destination_vault(dv_to_sig_to_vp, plan_data[\"destinationIn\"], 'in')\n",
    "\n",
    "    start_vp  = get_state_by_one_block([out_vp_call, in_vp_call], rebalance_block, autopool.chain)\n",
    "    plan_data['start_vp'] = start_vp\n",
    "\n",
    "    reblance_block_timestamp = autopool.chain.client.eth.get_block(rebalance_block)['timestamp']\n",
    "    current_timestamp = autopool.chain.client.eth.get_block('latest')['timestamp']\n",
    "\n",
    "    if reblance_block_timestamp + 30*24*3600 > current_timestamp:\n",
    "        end_vp = {}\n",
    "        block_30_days_in_future = None\n",
    "    else:\n",
    "        block_30_days_in_future = fetch_blocks_by_unix_timestamps_defillama(\n",
    "            [reblance_block_timestamp + 30*24*3600], autopool.chain\n",
    "        )[0]\n",
    "\n",
    "        end_vp = get_state_by_one_block([out_vp_call, in_vp_call], block_30_days_in_future, autopool.chain)\n",
    "\n",
    "    plan_data['end_vp'] = end_vp\n",
    "    plan_data['block_30_days_in_future'] = block_30_days_in_future\n",
    "    \n",
    "    return plan_data\n",
    "\n",
    "\n",
    "def fetch_and_augment_onchain_calc_plans(autopool: AutopoolConstants) -> dict:\n",
    "    AUGMENTED_PLANS_SAVE_DIR = WORKING_DATA_DIR / f'{autopool.name}_augmented_plans'\n",
    "    os.makedirs(AUGMENTED_PLANS_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "    events = get_full_table_as_df_with_tx_hash(\n",
    "        RebalanceEvents, where_clause=RebalanceEvents.autopool_vault_address == autopool.autopool_eth_addr\n",
    "    )\n",
    "\n",
    "    dv_to_sig_to_vp = build_dv_to_sig_to_vp(autopool)\n",
    "\n",
    "    def fetch_and_save_augmented_plans(row):\n",
    "        file_path = row['rebalance_file_path']\n",
    "        block = row['block']\n",
    "        augmented_plan = add_destination_summary_stats(dv_to_sig_to_vp, file_path, block, autopool)\n",
    "\n",
    "        with open(AUGMENTED_PLANS_SAVE_DIR / f\"{augmented_plan['rebalance_plan_json_key']}.json\", \"w\") as f:\n",
    "            json.dump(augmented_plan, f, indent=4)\n",
    "        # print(f\"Saved augmented plan to {AUGMENTED_PLANS_SAVE_DIR / f'{file_path}.json'}\")\n",
    "\n",
    "\n",
    "    # Process all rows with rebalance_file_path using ThreadPoolExecutor\n",
    "    filtered_events = events[events['rebalance_file_path'].notna()]\n",
    "    # Print autopool name and count of events without plans\n",
    "    events_without_plans = events[events['rebalance_file_path'].isna()]\n",
    "    print(f\"Autopool: {autopool.name}\")\n",
    "    print(f\"Number of events without rebalance plans: {len(events_without_plans)}\")\n",
    "\n",
    "    # with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    #     futures = [executor.submit(fetch_and_save_augmented_plans, row) for idx, row in filtered_events.iterrows()]\n",
    "        \n",
    "    #     for future in tqdm(as_completed(futures), total=len(futures), desc=\"Augmenting and saving plans\"):\n",
    "    #         try:\n",
    "    #             future.result()\n",
    "    #         except Exception as e:\n",
    "    #             print(f\"Error processing plan: {e}\")\n",
    "\n",
    "    # Sequential version\n",
    "    for idx, row in tqdm(filtered_events.iterrows(), total=len(filtered_events), desc=\"Augmenting and saving plans (sequential)\"):\n",
    "        # try:\n",
    "        fetch_and_save_augmented_plans(row)\n",
    "        # except Exception as e:\n",
    "        #     print(f\"Error processing plan: {e}\")\n",
    "\n",
    "    print(f\"Processed {len(filtered_events)} events\")\n",
    "\n",
    "\n",
    "def run_old_plans():\n",
    "    fetch_and_augment_onchain_calc_plans(AUTO_ETH)\n",
    "    fetch_and_augment_onchain_calc_plans(BASE_ETH)\n",
    "    # fetch_and_augment_onchain_calc_plans(BAL_ETH)\n",
    "    # fetch_and_augment_onchain_calc_plans(AUTO_LRT)\n",
    "    # fetch_and_augment_onchain_calc_plans(DINERO_ETH)\n",
    "run_old_plans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next step is to get a destination vault address -> what ever the sovler use sfor the virtual price exchange rate type call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# older comments and notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (668683560.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'snapshotTimestamp': 0,\n",
    "#  'name': 'Tokemak-Wrapped Ether-Instadapp ETH v2',\n",
    "#  'address': '0x2C7120dCCF1c14A37A26A4955475d45d34a3d7E7',\n",
    "#  'poolType': 'self',\n",
    "#  'pool': '0xA0D3707c569ff8C87FA923d3823eC5D81c98Be78',\n",
    "#  'underlying': '0xA0D3707c569ff8C87FA923d3823eC5D81c98Be78',\n",
    "#  'underlyingTokens': ['0xA0D3707c569ff8C87FA923d3823eC5D81c98Be78'],\n",
    "#  'underlyingTokenAmounts': [0],\n",
    "#  'underlyingReserves': [],\n",
    "#  'totalAprIn': 0.04768909754724683,\n",
    "#  'totalAprOut': 0.04778744504724683,\n",
    "#  'incentiveAPR': 0.0,\n",
    "#  'destLPValue': 0,\n",
    "#  'discountViolationAddFlag': [False],\n",
    "#  'discountViolationTrim1Flag': [False],\n",
    "#  'discountViolationTrim2Flag': [False],\n",
    "#  'ownedShares': 876435544936734498733,\n",
    "#  'totSupply': 0,\n",
    "#  'safePrice': 1.199678846454828,\n",
    "#  'spotPrice': 1.199706024959943,\n",
    "#  'tokenSpotPrice': [1.199706024959943],# why is there a .3bps sptead between the safe and spot price? I thought it was like aave\n",
    "#  'tokenSafePrice': [1.199678846454828],\n",
    "#  'flipFlag': False},\n",
    "\n",
    "\n",
    "\n",
    "# these are too old, not current\n",
    "# def build_last_snapshot_timestamp_call(destination_vault_address: str, underlyer_address: str):\n",
    "#     \"\"\"Build a call to get lastSnapshotTimestamp from underlyer\"\"\"\n",
    "#     return Call(\n",
    "#         underlyer_address,\n",
    "#         \"lastSnapshotTimestamp()(uint256)\",\n",
    "#         [(f\"{destination_vault_address}_timestamp\", identity_with_bool_success)]\n",
    "#     )\n",
    "\n",
    "# def build_last_virtual_price_call(destination_vault_address: str, underlyer_address: str):\n",
    "#     \"\"\"Build a call to get lastVirtualPrice from underlyer\"\"\"\n",
    "#     return Call(\n",
    "#         underlyer_address,\n",
    "#         \"lastVirtualPrice()(uint256)\",\n",
    "#         [(f\"{destination_vault_address}_vp\", safe_normalize_with_bool_success)]\n",
    "#     )\n",
    "\n",
    "# all_timestamp_calls = [\n",
    "#     build_last_snapshot_timestamp_call(destination_vault_address, underlyer_address)\n",
    "#     for destination_vault_address, underlyer_address in destination_vault_to_underlyer.items()\n",
    "#     if underlyer_address is not None\n",
    "# ]\n",
    "\n",
    "# all_last_vp_calls = [\n",
    "#     build_last_virtual_price_call(destination_vault_address, underlyer_address)\n",
    "#     for destination_vault_address, underlyer_address in destination_vault_to_underlyer.items()\n",
    "#     if underlyer_address is not None\n",
    "# ]\n",
    "\n",
    "# all_virtual_price_calls = all_timestamp_calls + all_last_vp_calls\n",
    "\n",
    "# vps = get_state_by_one_block(all_virtual_price_calls, autopool.chain.get_block_near_top(), autopool.chain)\n",
    "# vps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not working\n",
    "# valid_pools = {dest: pool for dest, pool in destination_vault_to_pool.items() if pool is not None}\n",
    "\n",
    "# # Build convertToAssets calls for each pool\n",
    "# convert_to_assets_calls = [\n",
    "#     Call(\n",
    "#         pool_address,\n",
    "#         [\"convertToAssets(uint256)(uint256)\", int(1e18)],\n",
    "#         [(f\"{destination_vault}_assets\", safe_normalize_with_bool_success)]\n",
    "#     )\n",
    "#     for destination_vault, pool_address in valid_pools.items()\n",
    "# ]\n",
    " #broke\n",
    "# # Execute the calls\n",
    "# pool_assets = get_state_by_one_block(convert_to_assets_calls, autopool.chain.get_block_near_top(), autopool.chain)\n",
    "# pool_assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plan_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplan_data\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plan_data' is not defined"
     ]
    }
   ],
   "source": [
    "plan_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mainnet-launch-FtycU18g-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
